{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8967eb7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK !\n"
     ]
    }
   ],
   "source": [
    "print(\"OK !\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "72831b58",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import PromptTemplate\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "# LangChain wrapper for Pinecone\n",
    "from langchain_community.vectorstores import Pinecone\n",
    "# Official Pinecone client\n",
    "from pinecone import Pinecone as PineconeClient\n",
    "\n",
    "from langchain.document_loaders import PyPDFLoader, DirectoryLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.llms import CTransformers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "68590761",
   "metadata": {},
   "outputs": [],
   "source": [
    "PINECONE_API_KEY = \"pcsk_4Fh75S_MG7KLkX6D67K5h4GgMBe6mikgyfQVg9yU1FyYsqisZG3rsyveHPSNSArtgSL6na\"\n",
    "PINECONE_API_ENV = \"gcp-starter\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2c951dd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extract data from the PDF\n",
    "def load_pdf(data):\n",
    "    loader = DirectoryLoader(data,\n",
    "                    glob=\"*.pdf\",\n",
    "                    loader_cls=PyPDFLoader)\n",
    "    \n",
    "    documents = loader.load()\n",
    "\n",
    "    return documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "14736ba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "extracted_data = load_pdf(\"../data/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f3358366",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Create text chunks\n",
    "def text_split(extracted_data):\n",
    "    text_splitter = RecursiveCharacterTextSplitter(chunk_size = 500, chunk_overlap = 20)\n",
    "    text_chunks = text_splitter.split_documents(extracted_data)\n",
    "\n",
    "    return text_chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8f6d7e9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of my chunk: 5859\n"
     ]
    }
   ],
   "source": [
    "text_chunks = text_split(extracted_data)\n",
    "print(\"length of my chunk:\", len(text_chunks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2a268872",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sentence-transformers in c:\\users\\indra\\anaconda3\\envs\\mchatbot\\lib\\site-packages (2.7.0)\n",
      "Requirement already satisfied: langchain in c:\\users\\indra\\anaconda3\\envs\\mchatbot\\lib\\site-packages (0.2.11)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.34.0 in c:\\users\\indra\\anaconda3\\envs\\mchatbot\\lib\\site-packages (from sentence-transformers) (4.41.2)\n",
      "Requirement already satisfied: tqdm in c:\\users\\indra\\anaconda3\\envs\\mchatbot\\lib\\site-packages (from sentence-transformers) (4.67.1)\n",
      "Requirement already satisfied: torch>=1.11.0 in c:\\users\\indra\\anaconda3\\envs\\mchatbot\\lib\\site-packages (from sentence-transformers) (2.8.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\indra\\anaconda3\\envs\\mchatbot\\lib\\site-packages (from sentence-transformers) (1.26.4)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\indra\\anaconda3\\envs\\mchatbot\\lib\\site-packages (from sentence-transformers) (1.7.1)\n",
      "Requirement already satisfied: scipy in c:\\users\\indra\\anaconda3\\envs\\mchatbot\\lib\\site-packages (from sentence-transformers) (1.15.3)\n",
      "Requirement already satisfied: huggingface-hub>=0.15.1 in c:\\users\\indra\\anaconda3\\envs\\mchatbot\\lib\\site-packages (from sentence-transformers) (0.23.2)\n",
      "Requirement already satisfied: Pillow in c:\\users\\indra\\anaconda3\\envs\\mchatbot\\lib\\site-packages (from sentence-transformers) (11.3.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\indra\\anaconda3\\envs\\mchatbot\\lib\\site-packages (from transformers<5.0.0,>=4.34.0->sentence-transformers) (3.19.1)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\indra\\anaconda3\\envs\\mchatbot\\lib\\site-packages (from transformers<5.0.0,>=4.34.0->sentence-transformers) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\indra\\anaconda3\\envs\\mchatbot\\lib\\site-packages (from transformers<5.0.0,>=4.34.0->sentence-transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\indra\\anaconda3\\envs\\mchatbot\\lib\\site-packages (from transformers<5.0.0,>=4.34.0->sentence-transformers) (2025.9.1)\n",
      "Requirement already satisfied: requests in c:\\users\\indra\\anaconda3\\envs\\mchatbot\\lib\\site-packages (from transformers<5.0.0,>=4.34.0->sentence-transformers) (2.32.5)\n",
      "Requirement already satisfied: tokenizers<0.20,>=0.19 in c:\\users\\indra\\anaconda3\\envs\\mchatbot\\lib\\site-packages (from transformers<5.0.0,>=4.34.0->sentence-transformers) (0.19.1)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in c:\\users\\indra\\anaconda3\\envs\\mchatbot\\lib\\site-packages (from transformers<5.0.0,>=4.34.0->sentence-transformers) (0.6.2)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\indra\\anaconda3\\envs\\mchatbot\\lib\\site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (2025.9.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\indra\\anaconda3\\envs\\mchatbot\\lib\\site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (4.15.0)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in c:\\users\\indra\\anaconda3\\envs\\mchatbot\\lib\\site-packages (from langchain) (2.0.43)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in c:\\users\\indra\\anaconda3\\envs\\mchatbot\\lib\\site-packages (from langchain) (3.12.15)\n",
      "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in c:\\users\\indra\\anaconda3\\envs\\mchatbot\\lib\\site-packages (from langchain) (4.0.3)\n",
      "Requirement already satisfied: langchain-core<0.3.0,>=0.2.23 in c:\\users\\indra\\anaconda3\\envs\\mchatbot\\lib\\site-packages (from langchain) (0.2.23)\n",
      "Requirement already satisfied: langchain-text-splitters<0.3.0,>=0.2.0 in c:\\users\\indra\\anaconda3\\envs\\mchatbot\\lib\\site-packages (from langchain) (0.2.2)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.17 in c:\\users\\indra\\anaconda3\\envs\\mchatbot\\lib\\site-packages (from langchain) (0.1.147)\n",
      "Requirement already satisfied: pydantic<3,>=1 in c:\\users\\indra\\anaconda3\\envs\\mchatbot\\lib\\site-packages (from langchain) (1.10.13)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in c:\\users\\indra\\anaconda3\\envs\\mchatbot\\lib\\site-packages (from langchain) (8.5.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in c:\\users\\indra\\anaconda3\\envs\\mchatbot\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in c:\\users\\indra\\anaconda3\\envs\\mchatbot\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\indra\\anaconda3\\envs\\mchatbot\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\indra\\anaconda3\\envs\\mchatbot\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.7.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\indra\\anaconda3\\envs\\mchatbot\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.6.4)\n",
      "Requirement already satisfied: propcache>=0.2.0 in c:\\users\\indra\\anaconda3\\envs\\mchatbot\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (0.3.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in c:\\users\\indra\\anaconda3\\envs\\mchatbot\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.20.1)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\indra\\anaconda3\\envs\\mchatbot\\lib\\site-packages (from langchain-core<0.3.0,>=0.2.23->langchain) (1.33)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\indra\\anaconda3\\envs\\mchatbot\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.3.0,>=0.2.23->langchain) (3.0.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\indra\\anaconda3\\envs\\mchatbot\\lib\\site-packages (from langsmith<0.2.0,>=0.1.17->langchain) (0.28.1)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in c:\\users\\indra\\anaconda3\\envs\\mchatbot\\lib\\site-packages (from langsmith<0.2.0,>=0.1.17->langchain) (3.11.3)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in c:\\users\\indra\\anaconda3\\envs\\mchatbot\\lib\\site-packages (from langsmith<0.2.0,>=0.1.17->langchain) (1.0.0)\n",
      "Requirement already satisfied: anyio in c:\\users\\indra\\anaconda3\\envs\\mchatbot\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (4.10.0)\n",
      "Requirement already satisfied: certifi in c:\\users\\indra\\anaconda3\\envs\\mchatbot\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (2025.8.3)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\indra\\anaconda3\\envs\\mchatbot\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (1.0.9)\n",
      "Requirement already satisfied: idna in c:\\users\\indra\\anaconda3\\envs\\mchatbot\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (3.10)\n",
      "Requirement already satisfied: h11>=0.16 in c:\\users\\indra\\anaconda3\\envs\\mchatbot\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (0.16.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\indra\\anaconda3\\envs\\mchatbot\\lib\\site-packages (from requests->transformers<5.0.0,>=4.34.0->sentence-transformers) (3.4.3)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\indra\\anaconda3\\envs\\mchatbot\\lib\\site-packages (from requests->transformers<5.0.0,>=4.34.0->sentence-transformers) (2.5.0)\n",
      "Requirement already satisfied: greenlet>=1 in c:\\users\\indra\\anaconda3\\envs\\mchatbot\\lib\\site-packages (from SQLAlchemy<3,>=1.4->langchain) (3.2.4)\n",
      "Requirement already satisfied: sympy>=1.13.3 in c:\\users\\indra\\anaconda3\\envs\\mchatbot\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (1.14.0)\n",
      "Requirement already satisfied: networkx in c:\\users\\indra\\anaconda3\\envs\\mchatbot\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\indra\\anaconda3\\envs\\mchatbot\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (3.1.6)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\indra\\anaconda3\\envs\\mchatbot\\lib\\site-packages (from sympy>=1.13.3->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\indra\\anaconda3\\envs\\mchatbot\\lib\\site-packages (from tqdm->sentence-transformers) (0.4.6)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in c:\\users\\indra\\anaconda3\\envs\\mchatbot\\lib\\site-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (1.3.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\users\\indra\\anaconda3\\envs\\mchatbot\\lib\\site-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (1.3.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\indra\\anaconda3\\envs\\mchatbot\\lib\\site-packages (from jinja2->torch>=1.11.0->sentence-transformers) (3.0.2)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\indra\\anaconda3\\envs\\mchatbot\\lib\\site-packages (from scikit-learn->sentence-transformers) (1.5.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\indra\\anaconda3\\envs\\mchatbot\\lib\\site-packages (from scikit-learn->sentence-transformers) (3.6.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\indra\\anaconda3\\envs\\mchatbot\\lib\\site-packages\\langchain_core\\_api\\deprecation.py:139: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 0.3.0. An updated version of the class exists in the langchain-huggingface package and should be used instead. To use it run `pip install -U langchain-huggingface` and import as `from langchain_huggingface import HuggingFaceEmbeddings`.\n",
      "  warn_deprecated(\n",
      "c:\\Users\\indra\\anaconda3\\envs\\mchatbot\\lib\\site-packages\\huggingface_hub\\file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vector length: 384\n"
     ]
    }
   ],
   "source": [
    "!pip install sentence-transformers langchain\n",
    "\n",
    "try:\n",
    "    from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "except ImportError:\n",
    "    from langchain.embeddings import HuggingFaceEmbeddings\n",
    "\n",
    "embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "\n",
    "# test\n",
    "vector = embeddings.embed_query(\"hello world\")\n",
    "print(\"Vector length:\", len(vector))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "456b714f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HuggingFaceEmbeddings(client=SentenceTransformer(\n",
       "  (0): Transformer({'max_seq_length': 256, 'do_lower_case': False}) with Transformer model: BertModel \n",
       "  (1): Pooling({'word_embedding_dimension': 384, 'pooling_mode_cls_token': False, 'pooling_mode_mean_tokens': True, 'pooling_mode_max_tokens': False, 'pooling_mode_mean_sqrt_len_tokens': False, 'pooling_mode_weightedmean_tokens': False, 'pooling_mode_lasttoken': False, 'include_prompt': True})\n",
       "  (2): Normalize()\n",
       "), model_name='sentence-transformers/all-MiniLM-L6-v2', cache_folder=None, model_kwargs={}, encode_kwargs={}, multi_process=False, show_progress=False)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8cf28f7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length 384\n"
     ]
    }
   ],
   "source": [
    "query_result = embeddings.embed_query(\"Hello world\")\n",
    "print(\"Length\", len(query_result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "42df117a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Data inserted successfully into Pinecone!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from pinecone import Pinecone, ServerlessSpec\n",
    "from langchain_community.vectorstores import Pinecone as PineconeStore\n",
    "\n",
    "# --- 1. Set API Key ---\n",
    "os.environ[\"PINECONE_API_KEY\"] = PINECONE_API_KEY\n",
    "\n",
    "# --- 2. Init Pinecone client ---\n",
    "pc = Pinecone(api_key=os.environ[\"PINECONE_API_KEY\"])\n",
    "\n",
    "# --- 3. Create index if not exists ---\n",
    "index_name = \"m-chat\"\n",
    "\n",
    "if index_name not in [i[\"name\"] for i in pc.list_indexes()]:\n",
    "    pc.create_index(\n",
    "        name=index_name,\n",
    "        dimension=len(embeddings.embed_query(\"hello world\")),  # e.g. 384 for MiniLM-L6-v2\n",
    "        metric=\"cosine\",\n",
    "        spec=ServerlessSpec(cloud=\"aws\", region=\"us-east-1\")   # change region if needed\n",
    "    )\n",
    "\n",
    "# --- 4. Get handle to index ---\n",
    "index = pc.Index(index_name)\n",
    "\n",
    "# --- 5. Insert your chunks into Pinecone via LangChain wrapper ---\n",
    "docsearch = PineconeStore.from_texts(\n",
    "    [t.page_content for t in text_chunks],\n",
    "    embeddings,\n",
    "    index_name=index_name,\n",
    "    namespace=\"medical-book\"\n",
    ")\n",
    "\n",
    "print(\"✅ Data inserted successfully into Pinecone!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2171ec24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result []\n"
     ]
    }
   ],
   "source": [
    "#If we already have an index we can load it like this\n",
    "docsearch=Pinecone.from_existing_index(\"medical-chatbot\", embeddings)\n",
    "\n",
    "query = \"What are Allergies\"\n",
    "\n",
    "docs=docsearch.similarity_search(query, k=3)\n",
    "\n",
    "print(\"Result\", docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ab31f0c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template=\"\"\"\n",
    "Use the following pieces of information to answer the user's question.\n",
    "If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
    "\n",
    "Context: {context}\n",
    "Question: {question}\n",
    "\n",
    "Only return the helpful answer below and nothing else.\n",
    "Helpful answer:\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5e69628a",
   "metadata": {},
   "outputs": [],
   "source": [
    "PROMPT=PromptTemplate(template=prompt_template, input_variables=[\"context\", \"question\"])\n",
    "chain_type_kwargs={\"prompt\": PROMPT}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "47fa16e4",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "Could not import `ctransformers` package. Please install it with `pip install ctransformers`",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\indra\\anaconda3\\envs\\mchatbot\\lib\\site-packages\\langchain_community\\llms\\ctransformers.py:64\u001b[0m, in \u001b[0;36mCTransformers.validate_environment\u001b[1;34m(cls, values)\u001b[0m\n\u001b[0;32m     63\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 64\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mctransformers\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m AutoModelForCausalLM\n\u001b[0;32m     65\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m:\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'AutoModelForCausalLM' from 'ctransformers' (unknown location)",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[40], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m llm\u001b[38;5;241m=\u001b[39m\u001b[43mCTransformers\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m../model/llama-2-7b-chat.ggmlv3.q4_0.bin\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      2\u001b[0m \u001b[43m                  \u001b[49m\u001b[43mmodel_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mllama\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[43m                  \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmax_new_tokens\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m512\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[43m                          \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtemperature\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m0.8\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\indra\\anaconda3\\envs\\mchatbot\\lib\\site-packages\\pydantic\\main.py:339\u001b[0m, in \u001b[0;36mpydantic.main.BaseModel.__init__\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\indra\\anaconda3\\envs\\mchatbot\\lib\\site-packages\\pydantic\\main.py:1050\u001b[0m, in \u001b[0;36mpydantic.main.validate_model\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\indra\\anaconda3\\envs\\mchatbot\\lib\\site-packages\\langchain_core\\utils\\pydantic.py:149\u001b[0m, in \u001b[0;36mpre_init.<locals>.wrapper\u001b[1;34m(cls, values)\u001b[0m\n\u001b[0;32m    146\u001b[0m                 values[name] \u001b[38;5;241m=\u001b[39m field_info\u001b[38;5;241m.\u001b[39mdefault\n\u001b[0;32m    148\u001b[0m \u001b[38;5;66;03m# Call the decorated function\u001b[39;00m\n\u001b[1;32m--> 149\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\indra\\anaconda3\\envs\\mchatbot\\lib\\site-packages\\langchain_community\\llms\\ctransformers.py:66\u001b[0m, in \u001b[0;36mCTransformers.validate_environment\u001b[1;34m(cls, values)\u001b[0m\n\u001b[0;32m     64\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mctransformers\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m AutoModelForCausalLM\n\u001b[0;32m     65\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m:\n\u001b[1;32m---> 66\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\n\u001b[0;32m     67\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCould not import `ctransformers` package. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     68\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease install it with `pip install ctransformers`\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     69\u001b[0m     )\n\u001b[0;32m     71\u001b[0m config \u001b[38;5;241m=\u001b[39m values[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconfig\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;129;01mor\u001b[39;00m {}\n\u001b[0;32m     72\u001b[0m values[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclient\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m AutoModelForCausalLM\u001b[38;5;241m.\u001b[39mfrom_pretrained(\n\u001b[0;32m     73\u001b[0m     values[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m     74\u001b[0m     model_type\u001b[38;5;241m=\u001b[39mvalues[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel_type\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     77\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconfig,\n\u001b[0;32m     78\u001b[0m )\n",
      "\u001b[1;31mImportError\u001b[0m: Could not import `ctransformers` package. Please install it with `pip install ctransformers`"
     ]
    }
   ],
   "source": [
    "llm=CTransformers(model=\"../model/llama-2-7b-chat.ggmlv3.q4_0.bin\",\n",
    "                  model_type=\"llama\",\n",
    "                  config={'max_new_tokens':512,\n",
    "                          'temperature':0.8})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d18e8f62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unexpected exception formatting exception. Falling back to standard exception\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\indra\\anaconda3\\envs\\mchatbot\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3508, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"C:\\Users\\indra\\AppData\\Local\\Temp\\ipykernel_16184\\439520835.py\", line 6, in <module>\n",
      "    qa = RetrievalQA.from_chain_type(\n",
      "  File \"c:\\Users\\indra\\anaconda3\\envs\\mchatbot\\lib\\site-packages\\langchain\\chains\\retrieval_qa\\base.py\", line 104, in from_chain_type\n",
      "    @classmethod\n",
      "  File \"c:\\Users\\indra\\anaconda3\\envs\\mchatbot\\lib\\site-packages\\langchain\\load\\serializable.py\", line 74, in __init__\n",
      "  File \"pydantic\\\\main.py\", line 347, in pydantic.main.BaseModel.__init__\n",
      "pydantic.error_wrappers.ValidationError: 1 validation error for RetrievalQA\n",
      "retriever\n",
      "  Can't instantiate abstract class BaseRetriever with abstract methods _get_relevant_documents (type=type_error)\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\indra\\anaconda3\\envs\\mchatbot\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2105, in showtraceback\n",
      "    stb = self.InteractiveTB.structured_traceback(\n",
      "  File \"c:\\Users\\indra\\anaconda3\\envs\\mchatbot\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1396, in structured_traceback\n",
      "    return FormattedTB.structured_traceback(\n",
      "  File \"c:\\Users\\indra\\anaconda3\\envs\\mchatbot\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1287, in structured_traceback\n",
      "    return VerboseTB.structured_traceback(\n",
      "  File \"c:\\Users\\indra\\anaconda3\\envs\\mchatbot\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1140, in structured_traceback\n",
      "    formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n",
      "  File \"c:\\Users\\indra\\anaconda3\\envs\\mchatbot\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1055, in format_exception_as_a_whole\n",
      "    frames.append(self.format_record(record))\n",
      "  File \"c:\\Users\\indra\\anaconda3\\envs\\mchatbot\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 955, in format_record\n",
      "    frame_info.lines, Colors, self.has_colors, lvals\n",
      "  File \"c:\\Users\\indra\\anaconda3\\envs\\mchatbot\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 778, in lines\n",
      "    return self._sd.lines\n",
      "  File \"c:\\Users\\indra\\anaconda3\\envs\\mchatbot\\lib\\site-packages\\stack_data\\utils.py\", line 144, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "  File \"c:\\Users\\indra\\anaconda3\\envs\\mchatbot\\lib\\site-packages\\stack_data\\core.py\", line 734, in lines\n",
      "    pieces = self.included_pieces\n",
      "  File \"c:\\Users\\indra\\anaconda3\\envs\\mchatbot\\lib\\site-packages\\stack_data\\utils.py\", line 144, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "  File \"c:\\Users\\indra\\anaconda3\\envs\\mchatbot\\lib\\site-packages\\stack_data\\core.py\", line 681, in included_pieces\n",
      "    pos = scope_pieces.index(self.executing_piece)\n",
      "  File \"c:\\Users\\indra\\anaconda3\\envs\\mchatbot\\lib\\site-packages\\stack_data\\utils.py\", line 144, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "  File \"c:\\Users\\indra\\anaconda3\\envs\\mchatbot\\lib\\site-packages\\stack_data\\core.py\", line 660, in executing_piece\n",
      "    return only(\n",
      "  File \"c:\\Users\\indra\\anaconda3\\envs\\mchatbot\\lib\\site-packages\\executing\\executing.py\", line 116, in only\n",
      "    raise NotOneValueFound('Expected one value, found 0')\n",
      "executing.executing.NotOneValueFound: Expected one value, found 0\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.vectorstores import Pinecone\n",
    "from langchain.chains import RetrievalQA\n",
    "retriever = docsearch.as_retriever(search_kwargs={\"k\": 2})\n",
    "\n",
    "# build RetrievalQA\n",
    "qa = RetrievalQA.from_chain_type(\n",
    "    llm=llm,\n",
    "    chain_type=\"stuff\",\n",
    "    retriever=retriever,\n",
    "    return_source_documents=True,\n",
    "    chain_type_kwargs=chain_type_kwargs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ef717f5",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'qa' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[84], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m      2\u001b[0m     user_input\u001b[38;5;241m=\u001b[39m\u001b[38;5;28minput\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInput Prompt:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m----> 3\u001b[0m     result\u001b[38;5;241m=\u001b[39m\u001b[43mqa\u001b[49m({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mquery\u001b[39m\u001b[38;5;124m\"\u001b[39m: user_input})\n\u001b[0;32m      4\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mResponse : \u001b[39m\u001b[38;5;124m\"\u001b[39m, result[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresult\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n",
      "\u001b[1;31mNameError\u001b[0m: name 'qa' is not defined"
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    user_input=input(f\"Input Prompt:\")\n",
    "    result=qa({\"query\": user_input})\n",
    "    print(\"Response : \", result[\"result\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mchatbot",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
